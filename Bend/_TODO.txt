

----[ TODO ]---------

  - email indexer test  
	 - add phrase match
	 - add proximity scoring
	 - add TFxIDF scoring (need numeric accumulators in the database!!) 
     - write a custom block handler for the index hits and efficient search intersection
     - compare indexing and query performance with lucene/xapian     

  - design/build [SimpleAtomicCommit] Attribute, and Attribute system
     - simply provide an atomic commit for a set of changes. Nobody (including us) should see the
	   changes until the transaction is committed. 
  
  - FIX histogram merges, so they don't create overlapping blocks!
     - IDEA-1: force a block boundary at the edge of any blocks not involved in the merge
	   - one way to do this is to force a block boundary at the end of every involved downstream block, though this is more
	     conservative than necessary
	   - another way, would be to check each time a block is added to the histogram, and if there were any blocks skipped,
	     record the need to force a block boundary before the start of that block
	   - yet another method is to use the histogram information to force a block-split, instead of a merge
	   - it would be much better if we could figure out how to avoid creating this problem to begin with!
	  - IDEA-2: let merge manger place the target block. If it overlaps, let it float to the higher gen.
	    - this doesn't solve anything. The new block will just be a new histo merge, continuing in an endless cycle. 		 
  
  - FIX segment_data_mismatch (block tombstone lost or ignored)

  - CLEANUP: make a 'new block range verify' that makes sure a new block range does not span an existing block range
    - though it'll need to ignore the blocks it's replacing. 
	- "correctness proof by induction", or some kind of expensive test mode to find and save error cases

  - CLEANUP:
    - on restart/recover, make sure segments are added to merge manager oldest-generation-to-newest
    - figure out the best way to fix IScanner so handle all operators  ( < <= > >= ) on all endpoints
    - check that we never try to write a row bigger than a microblock (how do we handle big rows?)
    - write scanForward() version of segment walk!! (use mergemanager segmentinfo map?)

  - TODO: make segment merge "apply" a truly atomic operation

  - DBG-GUI:
       - visualize block "fullness" and "tomstone to key ratio"
       - visualize log/workingsegment/checkpoint status
	   - visualize the disk/block address space
	   - show number of keys in the database (LayerManager will need to track this)
	   - figure out how LayerManager can notify listeners, such as DbgGUI (without performance dependence)

  - fix 'unmergable' higher generation blocks (i.e. increasing order insertion)
     - (a) use MergeManager to pick a the 'minGenerationForKeyrange"
	 - or, (b) allow MergeManager to recommend a 'rename' to a lower generation


  - make flushWorkingSegment an automatic part of LayerManager

  - cleanup    
    - use SegmentDescriptor class everywhere	
	- change generation to "int" everywhere.
	- make a SegmentPointer class that contains magic/address/length/checksum, to handle segment pointers
	- drop tombstones when writing into generation-0 (oldest)
	- fix "clear segment cache hack"... why does it need to be cleared?
	- scanForward/scanBackward should really have easy to use >/< operators in addition to <=/>=

	- add unit tests:
		- write a layertest for the deletion tombstone-shadow problem        
		- mergeSegments() unit test


	Q: what should be the type of keyparts? 

    Q: How do we assure a valid merge? (no generation inversion because of partial keyranges)
       - code to check that using the min-gen for a merge output is valid?

* TESTING
  - build synthetic tester... random row addition/deletion, where it turns on expensive
    "strong checking" of every segment operation, and database contents. Let it run
	for days to generate "failure data".   

* PERFORMANCE
  - fixes:
    - row-range consistant cache (for system metadata rows)
	- efficient row-scan instead of repeatin getNext()
	- sometimes it would be efficient to add more than one "top generation" block to a merge
  - tests:
    - simple text-indexer test
    - simulate iibench
       - insert 1B rows while maintaining three multi-column secondary indicies (i.e. insert 3B rows)
       - TARGET: 1000 rows per batch, tokudb 30k-15k inserts per sec, mysql 40k-876 inserts per sec

--------[ Bigger TODO items ]-----------

*** "table management"
  - ? integration of my RowPIPE prototype code, which is a generic type of "table management" to organize how multi-part keys are built
  - ? change system metadata to use rowpipe
  - ? bootstrap case of 'metadata to type/explain system metadata'

*** LinearAllocationRegion implementation (so two simultaneous allocators don't interleave)
  - can MergeManager trigger "defragmentation" of existing blocks? (i.e. schedule a merge of 10 fragmented blocks in the same generation)

*** row attributes for MVCC and locks
(a) introduce row-attribute concept (can affect commit, row visibility, etc.)
(b) attach MVCC attribute handler to writes, attach txn id to each row
(c) txn-id and MVCC attribute can transparently 'fall off' a row if txn commits, 

*** freelist
  - 'real' freelist handling
  - cleaner way to handle code and encoding of stored data, such as block pointers, freelist.. (binstruct?)

*** raw-byterange RegionManager
  - bounds checking on log-write, circular log, log-extension capability
  - bounds checking on segment size
  - encode segment length in SegmentInfo

*** Automated Replication
(a) 'lock' for old generations (i.e. checkpoint),
(b) copy locked data to replica
(c) create new 'lock' for newer data, goto (b), until we are up-to-date

*** try using C# sqlite sql implementation to throw SQL on top

- fix update semantics so "setValue" doesn't hack the value directly into the in-memory segment. It should simply commit the change packet and handleCommand() should cause the write to occur, just as it does in recovery. (i.e. recovery is the same as update)
- SegmentWriter needs buffered output (LogAppendWriter) - there was some problem with just dropping a buffered stream in place of the current streams
- Singleton keyparts for less allocation + faster comparisons
- stats tracking (qps, w_qps at 1 second interval)

*** consider enabling a workingSegmentFlush to operate as a merge, so we don't just write the blocks to then force a merge of most of them 
*** I/O scheduling (so log writes and segment writes don't thrash)
*** layer-avoidance, bloom filters
*** distributed shard manager
  - Cassandra performance tests - http://www.coreyhulen.org/?p=326
*** xml document database
    - http://www.ibm.com/developerworks/data/library/techarticle/dm-0606schiefer/

*** Network Interface

*** Hookup Hive/Pig for data-analysis
*** prototype "Palantir" data-slicing GUI

*** Interactive C# Shell mode?
   - http://tirania.org/blog/archive/2008/Sep-08.html


------------[ DONE ]--------------------
  
11/27 - basic text-indexer test with AND conjunction of terms is working
11/25 - test adjusting the merge threshold ratio based on the current maximum number of layers...
11/24 - fix runaway max-generation issue....  
11/24 - FIXED - as the MergeManager is generating merge candidates, when it descends another generation, 
        it needs to expand the start/end ranges to be inclusive of all the blocks in the previous generations!   
11/24 - BDSkipList, short circuit a case where an equal_ok key is found to return faster
11/24 - fixed merge bug that was causing invalid overlapping blocks (jeske)
11/23 - visualize merges as they occur (w/progress)
11/23 - color blocks based on has of key range (tomn)
11/23 - prevent visual 'generation skipping'  (where it skips generation-columns that have no data) (tomn)
11/23 - draw blocks the same height, with diagonal lines to indiciate key range alignment (tomn)
11/23 - write scanForward for the database (stand in until we write a real scanForward sorted-walk)
11/20 - added merge manager 'key histogram' merge-ratio computation as a fallback
11/20 - first incremental merge manager (+prevent holes from 'blocking' merges)
11/18 - make a "big test case" that shows off multiple layers of segments merging, with a debug visualization UI!
11/3 - first incremental block merge works
